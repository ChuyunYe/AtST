install.packages('parallel')
library(parallel)
res = mclapply(1:100,function(x){
x = rnorm(100)
y = mean(x)
return(y)
},mc.cores=2)
getwd()
write.csv(unlist(res),file='res.csv')
install.packages('MASS')
print(unlist(res),file='res.csv')
res = mclapply(1:100000,function(x){
x = rnorm(100)
y = mean(x)
return(y)
},mc.cores=96)
library(parallel)
res = mclapply(1:100000,function(x){
x = rnorm(100)
y = mean(x)
return(y)
},mc.cores=1)
Sys.sleep(1)
100000/60
res = mclapply(1:100,function(x){
x = rnorm(100)
y = mean(x)
Sys.sleep(1)
return(y)
},mc.cores=1)
10000/96
96*3
library(usethis)
library(devtools)
library(roxygen2)
# 检查
has_devel()
## 新建文件夹并设置工作目录至此文件夹下，之后创建的所有R包都在这个目录中。
setwd('/Users/emilyyip/Documents/MyPackages')
usethis::create_package('AtST')
?ncvreg
??apply
data_generating = function(seed,beta_M=NULL,gamma_A=NULL,
setting='1Med',A_dist='Bionomial',nsample=300){
#' @description This function is to generate data under different settings.
#' @param seed random seed
#' @param beta_M beta_M, d*1 matrix
#' @param gamma_A gamma_A, d*1 matrix
#' @param setting to indicate data generating setting
#' setting='1Med': single mediator
#' setting='MulMed_fix': multiple mediator with fixed sparsity
#' setting='MulMed_div': multiple mediator with diverge sparsity
#' @param A_dist to indicate the distribution of treatment variable A
#' A_dist='Bionomial': variable A is drawn from Bernoulli distribution with success probability 0.5.
#' A_dist='Uniform': variable A is drawn from Uniform distribution within intervel (-1,1).
#' A_dist='Normal': variable A is drawn from Normal distribution conditioning on |A|<1.
#' @param nsample sample size
#' @return a data list with X (confounder, matrix), A (treatment, vector), M (mediator, matrix), Y (outcome, vector)
set.seed(seed)
# featuring parameter
q = 2; d = 1
sd_M = 1/2; sd_Y = 1/2
# data generating
if (A_dist=='Bionomial') {
A = rbinom(n=nsample,size=1,prob=0.5)
}else if (A_dist=='Uniform') {
A = runif(n=nsample,min=-1,max=1)
}else if (A_dist=='Normal') {
sd_A = 2
A_bound = 1
para = 1/(pnorm(q=A_bound,mean=0,sd=sd_A)-pnorm(q=-A_bound,mean=0,sd=sd_A))
u = runif(n=nsample,min=0,max=1)
A = qnorm(p=u/para+pnorm(q=-A_bound,mean=0,sd=sd_A),mean=0,sd=sd_A)
}
if (setting=='1Med') {
X1 = rnorm(n=nsample,mean=0,sd=1)
X2 = rbinom(n=nsample,size=1,prob=0.5)
X = matrix(c(X1,X2),ncol=2,byrow=FALSE)
eps_M = rnorm(n=nsample,mean=0,sd=sd_M)
eps_Y = rnorm(n=nsample,mean=0,sd=sd_Y)
# M = 1 + A%*%gamma_A + X[,1] + X[,2] + eps_M
# Y = 1 + A + M%*%beta_M + X[,1] + X[,2] + eps_Y
M = 1 + A%*%gamma_A + sin(A)/sqrt(nsample) + X[,1] + X[,2] + eps_M
Y = 1 + A + M%*%beta_M + sin(M)/sqrt(nsample) + X[,1] + X[,2] + eps_Y
}else if (setting=='MulMed_fix') {
# featuring parameter
d = 1000
sd_M = 1; sd_Y = 1
X1_M_index = rep(1:2,length.out=d)
X1_Y_index = 1
X2_M_index = rep(1:2,length.out=d)
X2_Y_index = 1
# data generating
X1 = matrix(rnorm(n=nsample*10,mean=0,sd=0.5),nrow=nsample)
X2 = matrix(rbinom(n=nsample*10,size=1,prob=0.5),nrow=nsample)
X3 = matrix(runif(n=nsample*10,min=-1,max=1),nrow=nsample)
X4 = matrix(rnorm(n=nsample*10,mean=0,sd=0.5),nrow=nsample)
X5 = matrix(rbinom(n=nsample*10,size=1,prob=0.5),nrow=nsample)
X6 = matrix(runif(n=nsample*10,min=-1,max=1),nrow=nsample)
X7 = matrix(rnorm(n=nsample*10,mean=0,sd=0.5),nrow=nsample)
X8 = matrix(rbinom(n=nsample*10,size=1,prob=0.5),nrow=nsample)
X9 = matrix(runif(n=nsample*10,min=-1,max=1),nrow=nsample)
# X = cbind(X1,X2,X3,X4,X5,X6,X7,X8,X9)
X = cbind(X1,X2)
eps_M = matrix(rnorm(n=nsample*d,mean=0,sd=sd_M),nrow=nsample,ncol=d)
eps_Y = rnorm(n=nsample,mean=0,sd=sd_Y)
M = 1 + A%*%t(gamma_A) + X1[,X1_M_index] + X2[,X2_M_index] + eps_M
Y = 1 + A + M%*%beta_M + X1[,X1_Y_index] + X2[,X2_Y_index] + eps_Y
}else if (setting=='MulMed_div') {
# featuring parameter
d = 1000
sd_M = 1; sd_Y = 1
X_Y_index_seq = rep(1,9)
X_M_index_mat = matrix(c(rep(1:2,length.out=1000),rep(1:2,length.out=d),
rep(1:2,length.out=1000),rep(1:2,length.out=d),
rep(1:2,length.out=1000),rep(1:2,length.out=d),
rep(1:2,length.out=1000),rep(1:2,length.out=d),
rep(1:2,length.out=1000)),nrow=d)
# data generating
X1 = matrix(rnorm(n=nsample*10,mean=0,sd=0.5),nrow=nsample)
X2 = matrix(rbinom(n=nsample*10,size=1,prob=0.5),nrow=nsample)
X3 = matrix(runif(n=nsample*10,min=-1,max=1),nrow=nsample)
X4 = matrix(rnorm(n=nsample*10,mean=0,sd=0.5),nrow=nsample)
X5 = matrix(rbinom(n=nsample*10,size=1,prob=0.5),nrow=nsample)
X6 = matrix(runif(n=nsample*10,min=-1,max=1),nrow=nsample)
X7 = matrix(rnorm(n=nsample*10,mean=0,sd=0.5),nrow=nsample)
X8 = matrix(rbinom(n=nsample*10,size=1,prob=0.5),nrow=nsample)
X9 = matrix(runif(n=nsample*10,min=-1,max=1),nrow=nsample)
X = cbind(X1,X2,X3,X4,X5,X6,X7,X8,X9)
Mx = 0
Yx = 0
for (j in 1:floor(nsample^(1/3))) {
Mx = Mx + X[,((j-1)*10+1):(j*10)][,X_M_index_mat[,j]]
Yx = Yx + X[,((j-1)*10+1):(j*10)][,X_Y_index_seq[j]]
}
eps_M = matrix(rnorm(n=nsample*d,mean=0,sd=sd_M),nrow=nsample,ncol=d)
eps_Y = rnorm(n=nsample,mean=0,sd=sd_Y)
M = 1 + A%*%t(gamma_A) + Mx + eps_M
Y = 1 + A + M%*%beta_M + Yx + eps_Y
}
return(list(X=as.matrix(X), A=as.vector(A), M=as.matrix(M), Y=as.vector(Y)))
}
beta_M =  matrix(c(rep(0.5,10),rep(0,10)  ,rep(0,630),rep(0.5,350)),ncol=1)
gamma_A = matrix(c(rep(0,10),  rep(0.5,10),rep(0,630),rep(0.5,350)),ncol=1)
data.list.example = data_generating(seed=1,beta_M=beta_M,gamma_A=gamma_A,
setting='MulMed_fix',A_dist='Uniform',
nsample=500)
getwd()
save(data.list.example,file='data_list_example.RData')
usethis::use_data(data.list.example,data_list_example)
setwd('/Users/emilyyip/Documents/MyPackages/AtST')
usethis::use_data(data.list.example,data_list_example)
TestStatistics = function(data.list){
# data retrieving
X = data.list$X
A = data.list$A
M = data.list$M
Y = data.list$Y
d = ncol(M)
q = ncol(X)
n = nrow(X)
# tuning parameter setting
an = 0.15*n/log(n)
bn = 2.25*log(log(n))/(log((log(log(d)+1)+1))+1)
# penalty factors setting
penalty.factor_beta = c(rep(0,2),rep(1,q))
penalty.factor_gamma = c(rep(0,1),rep(1,q))
# do it for every M[,k] in a loop
hat_beta_M_seq = c();hat_gamma_A_seq = c()
hat_sigma2_beta_margin = c();hat_sigma2_gamma_margin = c()
hat_beta_gamma_per = NULL
Mk_per_func = function(Mk){
# penalized regression for Y~M[,k]
lambda_seq = sort(exp(seq(from=log(sqrt(1/n)/2),to=log(4),length.out=100)),
decreasing=T)
# ncvreg: bic
bic_beta = ncvreg(X=cbind(A,Mk,X),y=Y,family='gaussian',penalty='SCAD',
lambda=lambda_seq,
penalty.factor=penalty.factor_beta)
bic_seq_beta = n*log(bic_beta$loss/n)+
log(n)*apply(unname(bic_beta$beta),2,function(hat_beta_lambda){
sum(hat_beta_lambda!=0)
})
chosen_lambda_beta = lambda_seq[which.min(bic_seq_beta)]
hat_beta = bic_beta$beta[,which.min(bic_seq_beta)]
# estimators assignment of beta
hat_beta_A = hat_beta[2]
hat_beta_Mk = hat_beta[3]
hat_beta_X = hat_beta[4:(3+q)]
# estimated active sets of beta_X
hat_act_ind_beta_X = which(hat_beta_X!=0)
hat_act_num_beta_X = length(hat_act_ind_beta_X)
# estimated Y~M error terms and corresponding variance
pred_Y = predict(bic_beta,cbind(A,Mk,X),lambda=chosen_lambda_beta)
hat_eps_Yk = Y-pred_Y
# estimated variance matrix of hat_beta_M[k]
Bnk = cbind(rep(1,n),A,X[,hat_act_ind_beta_X])
hat_Sigma_Bk_Mk = t(Bnk)%*%matrix(Mk,ncol=1)/n
hat_Sigma_Bk_Bk = t(Bnk)%*%Bnk/n
hat_Sigma_Bk_Bk_Mk = hat_Sigma_Bk_Bk-hat_Sigma_Bk_Mk%*%t(hat_Sigma_Bk_Mk)/mean(Mk^2)
hat_sigma2_beta = mean(((1+as.numeric(t(hat_Sigma_Bk_Mk)%*%solve(hat_Sigma_Bk_Bk_Mk)%*%
hat_Sigma_Bk_Mk)/mean(Mk^2))*Mk
-as.vector(t(hat_Sigma_Bk_Mk)%*%solve(hat_Sigma_Bk_Bk_Mk)%*%t(Bnk)))^2*
(hat_eps_Yk^2))/(mean(Mk^2)^2)
# penalized regression for M[,k]~A
# ncvreg: bic
bic_gamma = ncvreg(X=cbind(A,X),y=Mk,family='gaussian',penalty='SCAD',
lambda=lambda_seq,
penalty.factor=penalty.factor_gamma)
bic_seq_gamma = n*log(bic_gamma$loss/n)+
log(n)*apply(unname(bic_gamma$beta),2,function(hat_gamma_lambda){
sum(hat_gamma_lambda!=0)
})
chosen_lambda_gamma = lambda_seq[which.min(bic_seq_gamma)]
hat_gamma = bic_gamma$beta[,which.min(bic_seq_gamma)]
# estimators assignment of gamma
hat_gamma_A = hat_gamma[2]
hat_gamma_X = hat_gamma[3:(q+2)]
hat_act_ind_gamma_X = which(hat_gamma_X!=0)
hat_act_num_gamma_X = length(hat_act_ind_gamma_X)
# estimated M[,k]~A error term[k] and corresponding variance[k]
pred_Mk = predict(bic_gamma,cbind(A,X),lambda=chosen_lambda_gamma)
hat_eps_Mk = Mk-pred_Mk
# estimated variance of hat_gamma[k]
Rnk = cbind(rep(1,n),X[,hat_act_ind_gamma_X])
hat_Sigma_Rk_A= t(Rnk)%*%matrix(A,ncol=1)/n
hat_Sigma_Rk_Rk = t(Rnk)%*%Rnk/n
hat_Sigma_Rk_Rk_A = hat_Sigma_Rk_Rk-hat_Sigma_Rk_A%*%t(hat_Sigma_Rk_A)/mean(A^2)
# estimated variance of hat_gamma_A[k]
hat_sigma2_gamma = mean(((1+as.numeric(t(hat_Sigma_Rk_A)%*%solve(hat_Sigma_Rk_Rk_A)%*%
hat_Sigma_Rk_A)/mean(A^2))*A
-as.vector(t(hat_Sigma_Rk_A)%*%solve(hat_Sigma_Rk_Rk_A)%*%t(Rnk)))^2*
(hat_eps_Mk^2))/(mean(A^2))^2
return(c(hat_beta_Mk,hat_sigma2_beta,hat_gamma_A,hat_sigma2_gamma))
}
for (k in 1:d) {
Mk = M[,k]
hat_beta_gamma_per = cbind(hat_beta_gamma_per,Mk_per_func(Mk))
}
hat_beta_M_seq = hat_beta_gamma_per[1,]
hat_sigma2_beta_margin = hat_beta_gamma_per[2,]
hat_gamma_A_seq = hat_beta_gamma_per[3,]
hat_sigma2_gamma_margin = hat_beta_gamma_per[4,]
T_beta = sqrt(n)*hat_beta_M_seq/sqrt(hat_sigma2_beta_margin)
T_gamma = sqrt(n)*hat_gamma_A_seq/sqrt(hat_sigma2_gamma_margin)
I1 = ((an*T_gamma^2)>(T_beta^2))
I2 = ((an*T_beta^2)>(T_gamma^2))
T_k_2 = (n*(hat_beta_M_seq*I1+hat_gamma_A_seq*I2)^2/
((hat_sigma2_beta_margin*I1+hat_sigma2_gamma_margin*I2+(1/n))*(1+1/sqrt(n))) +
I1*I2*abs(T_beta*T_gamma)/bn)
T_choice = I1 + 2*I2
res_vec_1 = c(T_k_2,T_beta,T_gamma,T_choice,hat_beta_M_seq,hat_gamma_A_seq,
hat_sigma2_beta_margin,hat_sigma2_gamma_margin)
# return(unname(res_vec_1))
return(unname(T_k_2))
}
lll = TestStatistics(data.list.example)
library(ncvreg)
lll = TestStatistics(data.list.example)
Tstat = lll
TStat = lll
p_value.seq = 1-pchisq(q=TStat,df=1)
SeqHyTest_FDR = function(p_value.seq,tuning_type,tuning,FDR){
allowed_tuning_type = c('DOS','Storey')
if (!tuning_type %in% allowed_tuning_type) {
stop("Invalid 'tuning_type'. Please choose either 'DOS' or 'Storey'.")
}
d = length(p_value.seq)
if (tuning_type=='DOS') {
tuning_seq = c(0.5,1)
sorted_p_value.seq = sort(p_value.seq,decreasing=F)
d_alpha.vec = c()
# d_alpha.mat = matrix(0,nrow=2,ncol=floor(d/2))
alp = tuning
for (k in 1:floor(d/2)) {
d_alpha.vec = c(d_alpha.vec,
(sorted_p_value.seq[2*k]-2*sorted_p_value.seq[k])/(k^alp))
# d_alpha.mat[a,k] = (sorted_p_value.seq[2*k]-2*sorted_p_value.seq[k])/(k^alp)
}
hat_k_alpha = which.max(d_alpha.vec)
# hat_k_alpha = apply(d_alpha.mat,1,which.max)
hat_pi_1 = (hat_k_alpha/d
- sorted_p_value.seq[hat_k_alpha])/(1-sorted_p_value.seq[hat_k_alpha])
hat_pi_0 = 1-hat_pi_1
# hat_pi_1_seq = (hat_k_alpha/d
#                 - sorted_p_value.seq[hat_k_alpha])/(1-sorted_p_value.seq[hat_k_alpha])
# hat_pi_0_seq = 1-hat_pi_1_seq
# for (a in 1:length(tuning_seq)) {
#   alp = tuning_seq[a]
#   for (k in 1:floor(d/2)) {
#     d_alpha.mat[a,k] = (sorted_p_value.seq[2*k]-2*sorted_p_value.seq[k])/(k^alp)
#   }
# }
# hat_k_alpha = apply(d_alpha.mat,1,which.max)
# hat_pi_1_seq = (hat_k_alpha/d
#                 - sorted_p_value.seq[hat_k_alpha])/(1-sorted_p_value.seq[hat_k_alpha])
# hat_pi_0_seq = 1-hat_pi_1_seq
}else if (tuning_type=='Storey') {
theta = tuning
hat_pi_0 = sum(p_value.seq>theta)/(d*(1-theta))
# tuning_seq = c(0.8,0.9)
# hat_pi_0_seq = c()
# for (theta in tuning_seq) {
#   hat_pi_0_seq = c(hat_pi_0_seq,sum(p_value.seq>theta)/(d*(1-theta)))
# }
}
hat_FDR = function(delta){
if (sum(p_value.seq<=delta)>=1) {
res = (hat_pi_0*delta)/(sum(p_value.seq<=delta)/d)
}else{
res = (hat_pi_0*delta)/(1/d)
}
return(res)
}
delta_seq = sort(seq(0,0.7,0.0001)^2,decreasing=T)
for (delta in delta_seq) {
hat_fdr = hat_FDR(delta=delta)
if (hat_fdr<FDR) {
break
}
}
accept_indicate = (p_value.seq>delta)
reject_indicate = 1 - accept_indicate
if (sum(reject_indicate)>0) {
FDP = sum(reject_indicate*true_indicate)/sum(reject_indicate)
}else{
FDP = 0
}
# return(list(delta=delta,hat_pi_0=hat_pi_0,FDP=FDP))
return(list(delta=delta,reject_indicator=reject_indicate))
# hat_FDR = function(delta){
#   if (sum(p_value.seq<=delta)>=1) {
#     res = (hat_pi_0*delta)/(sum(p_value.seq<=delta)/d)
#   }else{
#     res = (hat_pi_0*delta)/(1/d)
#   }
#   return(res)
# }
# delta_seq = sort(seq(0,0.7,0.0001)^2,decreasing=T)
# delta_choice = c()
#
# for (tune in 1:length(tuning_seq)) {
#   hat_pi_0 = hat_pi_0_seq[tune]
#   for (delta in delta_seq) {
#     hat_fdr = hat_FDR(delta=delta)
#     if (hat_fdr<FDR) {
#       break
#     }
#   }
#   delta_choice = c(delta_choice,delta)
# }
# return(list(delta_choice=delta_choice,hat_pi_0_seq=hat_pi_0_seq))
}
SeqHyTest_FDR(p_value.seq,tuning_type='DOS',tuning=1,FDR=0.2)
SeqHyTest_FDR = function(p_value.seq,tuning_type,tuning,FDR){
allowed_tuning_type = c('DOS','Storey')
if (!tuning_type %in% allowed_tuning_type) {
stop("Invalid 'tuning_type'. Please choose either 'DOS' or 'Storey'.")
}
d = length(p_value.seq)
if (tuning_type=='DOS') {
tuning_seq = c(0.5,1)
sorted_p_value.seq = sort(p_value.seq,decreasing=F)
d_alpha.vec = c()
# d_alpha.mat = matrix(0,nrow=2,ncol=floor(d/2))
alp = tuning
for (k in 1:floor(d/2)) {
d_alpha.vec = c(d_alpha.vec,
(sorted_p_value.seq[2*k]-2*sorted_p_value.seq[k])/(k^alp))
# d_alpha.mat[a,k] = (sorted_p_value.seq[2*k]-2*sorted_p_value.seq[k])/(k^alp)
}
hat_k_alpha = which.max(d_alpha.vec)
# hat_k_alpha = apply(d_alpha.mat,1,which.max)
hat_pi_1 = (hat_k_alpha/d
- sorted_p_value.seq[hat_k_alpha])/(1-sorted_p_value.seq[hat_k_alpha])
hat_pi_0 = 1-hat_pi_1
# hat_pi_1_seq = (hat_k_alpha/d
#                 - sorted_p_value.seq[hat_k_alpha])/(1-sorted_p_value.seq[hat_k_alpha])
# hat_pi_0_seq = 1-hat_pi_1_seq
# for (a in 1:length(tuning_seq)) {
#   alp = tuning_seq[a]
#   for (k in 1:floor(d/2)) {
#     d_alpha.mat[a,k] = (sorted_p_value.seq[2*k]-2*sorted_p_value.seq[k])/(k^alp)
#   }
# }
# hat_k_alpha = apply(d_alpha.mat,1,which.max)
# hat_pi_1_seq = (hat_k_alpha/d
#                 - sorted_p_value.seq[hat_k_alpha])/(1-sorted_p_value.seq[hat_k_alpha])
# hat_pi_0_seq = 1-hat_pi_1_seq
}else if (tuning_type=='Storey') {
theta = tuning
hat_pi_0 = sum(p_value.seq>theta)/(d*(1-theta))
# tuning_seq = c(0.8,0.9)
# hat_pi_0_seq = c()
# for (theta in tuning_seq) {
#   hat_pi_0_seq = c(hat_pi_0_seq,sum(p_value.seq>theta)/(d*(1-theta)))
# }
}
hat_FDR = function(delta){
if (sum(p_value.seq<=delta)>=1) {
res = (hat_pi_0*delta)/(sum(p_value.seq<=delta)/d)
}else{
res = (hat_pi_0*delta)/(1/d)
}
return(res)
}
delta_seq = sort(seq(0,0.7,0.0001)^2,decreasing=T)
for (delta in delta_seq) {
hat_fdr = hat_FDR(delta=delta)
if (hat_fdr<FDR) {
break
}
}
accept_indicate = (p_value.seq>delta)
reject_indicate = 1 - accept_indicate
# if (sum(reject_indicate)>0) {
#   FDP = sum(reject_indicate*true_indicate)/sum(reject_indicate)
# }else{
#   FDP = 0
# }
# return(list(delta=delta,hat_pi_0=hat_pi_0,FDP=FDP))
return(list(delta=delta,reject_indicator=reject_indicate))
# hat_FDR = function(delta){
#   if (sum(p_value.seq<=delta)>=1) {
#     res = (hat_pi_0*delta)/(sum(p_value.seq<=delta)/d)
#   }else{
#     res = (hat_pi_0*delta)/(1/d)
#   }
#   return(res)
# }
# delta_seq = sort(seq(0,0.7,0.0001)^2,decreasing=T)
# delta_choice = c()
#
# for (tune in 1:length(tuning_seq)) {
#   hat_pi_0 = hat_pi_0_seq[tune]
#   for (delta in delta_seq) {
#     hat_fdr = hat_FDR(delta=delta)
#     if (hat_fdr<FDR) {
#       break
#     }
#   }
#   delta_choice = c(delta_choice,delta)
# }
# return(list(delta_choice=delta_choice,hat_pi_0_seq=hat_pi_0_seq))
}
SeqHyTest_FDR(p_value.seq,tuning_type='DOS',tuning=1,FDR=0.2)
library(AtST)
library(devtools)
devtools::install_github('ChuyunYe/AtST')
library(AtST)
library(AtST)
file.edit('DESCRIPTION')
?person
